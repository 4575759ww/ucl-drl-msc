\chapter{Conclusion and Discussion}
\label{chapterlabel4}

\section{Summary}

\section{Future Work}

-More robust definition of the simulated environment

--robust model of user behaviour

--using a live recommender system

--monte carlo tree search

-Try to solve the problem using the Q-learning Model-based acceleration algorithm: Normalized Advantage Functions (NAF) to apply Q-learning with experience replay to continuous tasks. it outperforms actor-critic based algorithm (DDPG)

-test the model using dataset with higher sparsity level
