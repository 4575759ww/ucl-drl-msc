\chapter{Introduction}
\label{chapterlabel1}

\section{Problem Overview}

The volume of information available on the internet have been increasing rapidly with the explosive growth of the World Wide Web, e-Commerce and other online services, making difficult for users to find relevant products in a short period of time. To avoid this problem, many websites use recommendation systems to help customers to find items that satisfies their needs\cite{resnick1997recommender}. Suggestions for books on Amazon, or movies on Netflix, are real-world examples of Recommender Systems (RS) that demonstrate that the evolution of RS and the web should go hand-in-hand. As a result, the final goal of a RS is to efficiently manage an ever growing set of items and generate meaningful recommendations to a collection of users with common interests.

The design of such recommendation engines depends on the domain and the particular characteristics of the data available. While \textit{Collaborative Filtering} systems analyze historical interactions alone, \textit{Content-based} RS systems are based on user profile attributes; and finally, \textit{hybrid} techniques combine both of these designs. Latest studies in CF\cite{bobadilla2013recommender} showed that combining conceptual and usage information can improve the quality of web recommendation.

Current RS typically act in a \textit{greedy} manner by recommending items with the highest user ratings. However, greedy recommendations are suboptimal over the long term. This approach does not actively gather information on user preferences and fails to recommend novel songs that are potentially interesting. A successful recommender system must balance the need to explore user preferences and to exploit this information for recommendation.

Therefore, the architecture of recommender systems and their evaluation on real-world problems is an active area of research. In fact, RS have found an active application area for diverse Information Retrieval, Web Mining and Machine Learning techniques\cite{bobadilla2013recommender}. Reinforcement learning\cite{sutton1998reinforcement} for example, has been suited to solve the recommendation problem. In general, once a user makes her choice based on a list of recommendations given by a RS, a new list of recommended items is then presented. Thus, the recommendation process can be thought as a sequential process, where users choices are sequential by nature (e.g. a user buy a book by the author of a recent book we liked). 

Indeed, reinforcement learning has demonstrated to be a potentially effective approach in the domain and particularly good to solve the cold-start problem and in some extent, the exploration/exploitation trade-off\cite{shani2005mdp}. Nevertheless, it has received relatively little attention and found only limited application.

On the other hand, most recent research\cite{wang2015collaborative} have focused on making a generalization of recent advances in Deep Learning\cite{bengio2013representation} from Identically and Independently Distributed (i.i.d.) input to the non-i.i.d. (CF-based) input, and propose hierarchical Bayesian models that jointly performs deep representation learning for the content information and CF for estimating the ratings matrix. Experiments carried out shown that Deep Learning approaches can significantly outperform the state of the art. As a result, current research has been getting involved on using deep representational approaches that can lead to better recommendations.

Furthermore, a recent work presented by Dulac-Arnold et al. on deep reinforcement learning in large discrete action spaces\cite{Dulac-Arnold2015} presented a new policy architecture that not only allows reinforcement learning methods to be applied to large-scale learning problems, and to operate efficiently with a large number of actions, but also can generalize over the action set in logarithmic time. This algorithm showed to a promising convergence of the model among different continuous environments, where a simulated recommender system was also considered.

The main objective of this project is to show that a deep reinforcement learning model is able to perform well under a recommendation system environment and generate good recommendations to users over a large set of items. After defining a simulated recommendation system environment under the Open AI gym framework, the performance of the reinforcement agents based on the Deep Deterministic Policy Gradient algorithm with k-nearest neighbors (kNN) and Factorization Machine variants are compared. [***](Missing explanation of experiments and conclusions)

\section{Dissertation Objectives and Structure}

The remaining chapters of this report are organized as follows. Chapter \ref{sec:chapterlabel2} defines the recommender problem and introduces Reinforcement Learning. Following, it reviews some related work that has been made for modeling recommender systems using reinforcement learning approaches and deep learning. The proposed model and its implementation details are presented in Chapter \ref{sec:chapterlabel3}, while the experimental evaluation and results are analyzed in Chapter \ref{sec:chapterlabel4}. Finally, we present a summary of lessons learned and conclusions, and propose some ideas for future work.


%Inline citation: \bibentry{example-citation}
